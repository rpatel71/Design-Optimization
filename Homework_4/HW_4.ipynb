{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP042TOVeVTx86b43zCB7d/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rpatel71/Design-Optimization/blob/main/Homework_4/HW_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Design Optimization: Homework-4: Problem-4"
      ],
      "metadata": {
        "id": "gmuXnoprZBYT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "n5k3fLi60ZYt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import torch as t\n",
        "from torch.autograd import Variable\n",
        "from torch.autograd.functional import jacobian\n",
        "from numpy.linalg import inv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fun = lambda x: (x[0] ** 2 + x[1] ** 2 + x[2] ** 2)   # Objective function\n",
        "const1 = lambda x: ((x[0] ** 2) / 4) + ((x[1] ** 2) / 5) + (((x[2] ** 2) / 25) - 1)   # Constraint 1 from the given constraints\n",
        "const2 = lambda x: (x[0] + x[1] - x[2])   # Constraint 2 from the given constaints\n",
        "\n",
        "x = Variable(t.tensor([1, 1., 1.]), requires_grad=True)\n",
        "h = t.tensor([const1(x), const2(x)])   # h is an array of constraints\n",
        "\n",
        "print(h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwj3RIsz2MJc",
        "outputId": "1c1dcf5c-5c56-4271-9e8c-88f4c6f14de8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.5100,  1.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we know that, we have n=3 and constraints m=2. \n",
        "\n",
        "So, we have Decision variables = n - m = 1, and State variables = m = 2.\n",
        "\n",
        "So, Decision variables (d) = [x1] and state variables (s) = [x2, x3]"
      ],
      "metadata": {
        "id": "uYHbgQ-RnYcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def red_grad(fun, const1, const2, x): # This function calculates the Reduced Gradient\n",
        "  # compute jacobian for the function and constraints\n",
        "  jac = t.zeros(3, 3)\n",
        "  jac[0] = jacobian(fun, x)\n",
        "  jac[1] = jacobian(const1, x)\n",
        "  jac[2] = jacobian(const2, x)\n",
        "\n",
        "  # Variables we need, to calculate reduced function\n",
        "  dfdd = jac[0,0]\n",
        "  dfds = jac[0,1:]\n",
        "  dhds = jac[1:,1:]\n",
        "  dhdd = jac[1:,0]\n",
        "\n",
        "  # Finding the reduced gradient\n",
        "  inv_dhds = t.pinverse(dhds)\n",
        "  dfds_inv_dhds = t.matmul(dfds, inv_dhds)\n",
        "  red_grad = dfdd - t.matmul(dfds_inv_dhds, dhdd)\n",
        "\n",
        "  return red_grad, dfdd, dfds, dhds, dhdd"
      ],
      "metadata": {
        "id": "v2-VK1CwnNzL"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a function which improves x for line search\n",
        "def imp_x(a, x):\n",
        "  x_imp = t.zeros(3)\n",
        "  red_g, dfdd, dfds, dhds, dhdd = red_grad(fun, const1, const2, x)\n",
        "  x_imp[0] = x[0] - a*red_g\n",
        "  inv_dhds = t.pinverse(dhds)\n",
        "  x_imp[1] = x[1] - (a*t.matmul(inv_dhds, dhdd) * red_g)\n",
        "  return x_imp\n",
        "\n",
        "# Define Line search algorithm\n",
        "def line_search(x, max_iter):\n",
        "  iter = 0  # iterations\n",
        "  a = 1 # Alpha\n",
        "  tr = 0.5\n",
        "  f = fun(imp_x(a, x))\n",
        "  red_g, dfdd, dfds, dhds, dhdd = red_grad(fun, const1, const2, x)\n",
        "  phi = fun(x) - (tr * a * (red_g ** 2))\n",
        "  while f > phi and iter < max_iter:\n",
        "    a = 0.5*a\n",
        "    f = fun(imp_x(a, x))\n",
        "    phi = fun(x) - (tr * a * (red_g ** 2))\n",
        "    iter += 1\n",
        "  return a"
      ],
      "metadata": {
        "id": "xdJy8y_WvTWc"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function of Levenberg -Marquardt Algorithm\n",
        "def Lev_Marq(x):\n",
        "  lam = 1.\n",
        "  mod = t.norm(h)\n",
        "  while mod > 1e-06:\n",
        "    red_g, dfdd, dfds, dhds, dhdd = red_grad(fun, const1, const2, x)\n",
        "    with t.no_grad():\n",
        "      inv = t.pinverse(t.matmul(dhds.T, dhds) + lam * t.eye(2))\n",
        "      calc = t.matmul(t.matmul(inv, dhds.T), h)\n",
        "      x[1:] = x[1:] - calc\n",
        "    mod = t.norm(h)\n",
        "  return x"
      ],
      "metadata": {
        "id": "1TSTS5-o45D2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zYHvALok5B3t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}