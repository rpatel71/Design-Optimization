{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpSWOCpTkctMeABarsuPWb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rpatel71/Design-Optimization/blob/main/Homework_5/hw5_sqp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing all the libraries\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import torch as t"
      ],
      "metadata": {
        "id": "0at6zUO7sZ-a"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qeNoc9zV6w1f"
      },
      "outputs": [],
      "source": [
        "# defining the objective function as well as inequality constraints\n",
        "function = lambda x: x[0]**2 + (x[1] - 3)**2\n",
        "g_1 = lambda x: x[1]**2 - 2*x[0]\n",
        "g_2 = lambda x: (x[1]-1)**2 + 5*x[0]-15\n",
        "\n",
        "grad_fun = lambda x : t.tensor([[2 * x[0], 2 * (x[1] - 3)]])\n",
        "grad_g_1 = lambda x : t.tensor([[-2, 2 * x[1]]])\n",
        "grad_g_2= lambda x: t.tensor([[5, 2 * (x[1] - 1)]])\n",
        "\n",
        "g = lambda x: t.tensor([g_1(x), g_2(x)])\n",
        "grad_g = lambda x: t.tensor[grad_g_1(x), grad_g_2(x)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function for updating weights for the merit function\n",
        "def update_weights(mu, w, iter):\n",
        "  if iter>0:\n",
        "    w = t.max(abs(mu), 0.5 *(w + abs(mu)))\n",
        "  else:\n",
        "    w = abs(mu)\n",
        "  return w\n",
        "\n",
        "# function which calculates F(alpha)\n",
        "def fun_alp(x, w, alpha, s):\n",
        "  new_fun = function(x + alpha*s) +  w[0,:] * max(0, g_1(x + alpha*s)) + w[1,:]* max(0, g_2(x + alpha*s))\n",
        "  return new_fun"
      ],
      "metadata": {
        "id": "N8zOWzWP3Zfr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# funciton for calculating the armijo linesearch algorithm\n",
        "def line_Search(x, mu, w, s, iter):\n",
        "  t = 0.5\n",
        "  alpha = 1\n",
        "  w = update_weights(mu, w, iter)\n",
        "  if g_1(x) <= 0:\n",
        "    Dg1Da = 0\n",
        "  else:\n",
        "    Dg1Da = t.matmul(grad_g_1(x), s)\n",
        "\n",
        "  if g2(x) <= 0:\n",
        "    Dg2Da = 0\n",
        "  else:\n",
        "    Dg2Da = t.matmul(grad_g_1(x), s)\n",
        "  \n",
        "  dfun_da = t.matmul(grad_fun(x), s) + (w[0, :] * Dg1Da + w[1, :] * Dg2Da)\n",
        "\n",
        "  phi = lambda x, t, alpha, w, dfun_da: fun_alp(x, w, 0, 0) + t * alpha * dfun_da\n",
        "\n",
        "  while phi(x, t, alpha, w, dfun_da) < fun_alp(x, w, alpha, s):\n",
        "    alpha = alpha/2\n",
        "  return alpha, w"
      ],
      "metadata": {
        "id": "GGbyli-h9aC_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for approximating the Hessian via Broyden-Fletcher-Goldfarb-Shanno(BFGS) Method\n",
        "def bfgs(x, Lxx, s, mu, alpha):\n",
        "  grad_l_k = grad_fun(x) + t.matmul(mu.T, g(x))\n",
        "  x_up = x + s *alpha \n",
        "  grad_l_kp1 = grad_fun(x) + t.matmul(mu.T, g(x_up))\n",
        "\n",
        "  delt_l = grad_l_kp1 - grad_l_k\n",
        "\n",
        "  Q = t.matmul((t.matmul(alpha*s).T, Lxx), (alpha*s))\n",
        "  if t.matmul((alpha*s).T, delt_l.T) >= 0.2 * t.matmul(t.matmul((alpha*s).T, Lxx), (alpha*s)):\n",
        "    th = 1\n",
        "  else:\n",
        "    th = 0.8*Q / (Q-t.matmul((alpha*s).T, delt_l.T))\n",
        "  y = th * delt_l.T + (1-th)*t.matmul(Lxx, (alpha*s))\n",
        "  Lxx = Lxx + t.matmul(y, y.T) / t.matmul(y.T, s) - t.matmul(t.matmul(Lxx, s), t.matmul(s.T, Lxx))/t.matmul(t.matmul(s.T, Lxx), s)\n",
        "  return Lxx"
      ],
      "metadata": {
        "id": "yDA5nzhiD-jk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_lag_multiplier(mu, act_set):\n",
        "  mu_check = 0\n",
        "  if len(mu) == 0 or min(mu) > 0:\n",
        "    mu_check = 1\n",
        "  else:\n",
        "    mu_idx = np.argmin(np.array(mu))\n",
        "    mu = mu[mu!=min(mu)]\n",
        "    act_set.pop(mu_idx)\n",
        "  return act_set, mu_check, mu"
      ],
      "metadata": {
        "id": "gRAN3KJsL_4U"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the QP subproblem solver\n",
        "def sol_qp(x, Lxx):\n",
        "  act_set = []\n",
        "  init_A = t.cat((grad_g_1, grad_g_2), 0)\n",
        "  init_B = t.tensor([[g_1(x), g_2(x)]]).T\n",
        "  init_mu = t.zeros((init_B.shape[0], 1))\n",
        "  mu = []\n",
        "  while True:\n",
        "    if len(act_set) == 0:\n",
        "      s_mu = t.matmul(t.linalg.inv(Lxx), -grad_fun(x).T)\n",
        "      s = s_mu[:2, :1]\n",
        "    if len(act_set) > 0:\n",
        "      if len(act_set) == 1:\n",
        "        A = init_A[act_set[0], :].reshape(1,-1)\n",
        "        B = init_B[act_set[0], :].reshape(1, 1)\n",
        "      if len(act_set) == 2:\n",
        "        A = init_A\n",
        "        B = init_B\n",
        "      \n",
        "      z = t.zeros((A.shape[0], A.shape[0]))\n",
        "      mat = t.cat((t.cat((Lxx, A.T), 1), t.cat((A, z), 1)), 0)\n",
        "      j = t.cat((-grad_fun(x).T, -B), 0)\n",
        "      s_mu = t.matmul(t.linalg.inv(mat), j)\n",
        "      s = s_mu[:2, :]\n",
        "      mu = s_mu[2:, :]\n",
        "    \n",
        "    if len(mu)==1:\n",
        "      init_mu[0] = s_mu[2:3, :]\n",
        "    if len(mu)==2:\n",
        "      init_mu[0] = s_mu[2:3, :]\n",
        "      init_mu[1] = s_mu[3:, :]\n",
        "\n",
        "    const_sqp = t.round((t.matmul(init_A, s.reshape(-1,1)) + init_B))\n",
        "    act_set, che_mu, mu = check_lag_multiplier(mu, act_set)\n",
        "\n",
        "    if t.max(const_sqp) <=0 and che_mu==1:\n",
        "      return s, init_mu\n",
        "    else:\n",
        "      indx = np.argmax(const_sqp)\n",
        "      act_set.append(indx)\n",
        "      act_set = np.unique(np.array(act_set)).tolist()"
      ],
      "metadata": {
        "id": "P5F5X26xTrRY"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}